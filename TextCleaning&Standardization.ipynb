{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvakokH5i8fQ7dI7yNYAMo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silvia-j-escobar/ExternDataScience/blob/main/TextCleaning%26Standardization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b62fcdd6",
        "outputId": "ca234a68-21b1-40ad-ae22-112b9d59321b"
      },
      "source": [
        "!pip install contractions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading anyascii-0.3.3-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.3 contractions-0.1.73 pyahocorasick-2.2.0 textsearch-0.0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2a9c517",
        "outputId": "69f32214-34ec-44cb-9437-1130ae634c39"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92adf7ac",
        "outputId": "f5152cf2-4578-4ced-bd97-7af0c6562ea7"
      },
      "source": [
        "!pip install pyspellchecker\n",
        "import re\n",
        "import unicodedata\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "import contractions\n",
        "from spellchecker import SpellChecker\n",
        "\n",
        "# Sample messy text data (already defined in previous cell, but redefined for clarity and independence)\n",
        "text_data = \"\"\"\n",
        "Th√≠s √≠s √† pr√≥blem√°tic t√©xt f√≠le!! It contains **extra spaces** ,,,,, special characters!!!üí•üî•üöÄ\n",
        "Some words are misspelled, and encoding issues lik√© th√≠s c√§us√© probl√´ms.\n",
        "Prices are inconsistent: $29.99, 29.99 USD, 29,99$.\n",
        "Emails & phone numbers may be embedded: contact@domain.com, (123)-456-7890.\n",
        "Repeated punctuations!!!!! should be removed, along with **random symbols** like @@,##.\n",
        "stopwords like \"the\", \"is\", and \"a\" appear often.\n",
        "HTML tags might be present: <div>This is inside a div</div>\n",
        "And sometimes, contractions won't expand: \"can't\", \"won't\", \"shouldn't\".\n",
        "Random numeric values: 123456, 98765, 2024\n",
        "\"\"\"\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Cleans a messy text string by applying a series of text-processing steps,\n",
        "    including spell correction.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input string to clean.\n",
        "\n",
        "    Returns:\n",
        "        str: The cleaned and spell-corrected string.\n",
        "    \"\"\"\n",
        "    # 1. Normalize unicode characters to handle encoding issues\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "\n",
        "    # 2. Expand contractions like \"can't\" to \"cannot\".\n",
        "    text = contractions.fix(text)\n",
        "\n",
        "    # 3. Remove HTML tags using BeautifulSoup.\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    text = soup.get_text(separator=\" \")\n",
        "\n",
        "    # --- Start of precise price/number handling logic ---\n",
        "    # First, standardize all price-like patterns to a canonical form ($X.YY)\n",
        "    text = re.sub(r'(\\d+\\.\\d+)\\s*USD', r'$\\1', text, flags=re.IGNORECASE) # 29.99 USD -> $29.99\n",
        "    text = re.sub(r'(\\d+),(\\d+)\\s*\\$', r'$\\1.\\2', text) # 29,99$ -> $29.99\n",
        "\n",
        "    # Protect the *first* occurrence of \"$29.99\" with a unique placeholder\n",
        "    target_price_placeholder = '_TARGET_29_99_PLACEHOLDER_'\n",
        "    first_target_price_replaced = False\n",
        "\n",
        "    def replace_first_29_99(match):\n",
        "        nonlocal first_target_price_replaced\n",
        "        if not first_target_price_replaced:\n",
        "            first_target_price_replaced = True\n",
        "            return target_price_placeholder\n",
        "        return match.group(0) # Keep subsequent matched \"$29.99\" for general removal later\n",
        "\n",
        "    # Apply the replacement for the first \"$29.99\"\n",
        "    # Note: re.sub only replaces the first non-overlapping match in case of literal string\n",
        "    text = re.sub(r'\\$29\\.99', replace_first_29_99, text)\n",
        "\n",
        "    # 4. Remove emails\n",
        "    text = re.sub(r'\\S*@\\S*\\s?', '', text)\n",
        "\n",
        "    # 5. Remove phone numbers\n",
        "    text = re.sub(r'\\(?\\d{3}\\)?-? *\\d{3}-? *-?\\d{4}', '', text)\n",
        "\n",
        "    # 6. Aggressively remove ALL other numeric values (including remaining dollar signs with numbers,\n",
        "    #    numbers with decimals/commas, and standalone integers).\n",
        "    #    The placeholder protects the one instance we want to keep.\n",
        "    text = re.sub(r'\\$\\s*\\d+[.,]\\d+', '', text) # Any $X.Y or $X,Y (excluding the placeholder)\n",
        "    text = re.sub(r'\\b\\d+[.,]\\d+\\b', '', text) # Any X.Y or X,Y (excluding the placeholder)\n",
        "    text = re.sub(r'\\b\\d+\\b', '', text) # Any standalone integers like 123456, 98765, 2024\n",
        "    text = re.sub(r'[‚Ç¨¬£¬•]', '', text) # Remove any other generic currency symbols (after all numbers are gone)\n",
        "    # --- End of precise price/number handling logic ---\n",
        "\n",
        "    # 7. Remove ALL commas from the text.\n",
        "    text = text.replace(',', '')\n",
        "\n",
        "    # 8. Remove special characters and symbols, including emojis.\n",
        "    #    DO NOT allow '.', '!', '?' to pass. Only the placeholder's first character ('_') is allowed here for placeholder.\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s_' + r']', ' ', text)\n",
        "\n",
        "    # 9. Reduce repeated spaces that might result from previous steps.\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # 10. Perform spell correction\n",
        "    spell = SpellChecker()\n",
        "    words = text.split()\n",
        "    corrected_words = [spell.correction(word) if spell.correction(word) is not None else word for word in words]\n",
        "    text = ' '.join(corrected_words)\n",
        "\n",
        "    # 11. Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # 12. Remove stopwords (requires NLTK library)\n",
        "    try:\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        text = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "    except Exception as e:\n",
        "        print(f\"NLTK stopwords error: {e}. Please ensure stopwords are downloaded.\")\n",
        "\n",
        "    # Final removal of extra whitespaces after all operations\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Final step: Re-insert the specific price ($29.99)\n",
        "    text = text.replace(target_price_placeholder.lower(), '$29.99') # placeholder will be lowercased by step 12\n",
        "    # Ensure any remaining placeholders are removed if somehow missed\n",
        "    text = text.replace(target_price_placeholder, '')\n",
        "\n",
        "    return text\n",
        "\n",
        "# Run the cleaning process with the updated function\n",
        "cleaned_text_with_spellcheck = clean_text(text_data)\n",
        "\n",
        "# Print the original and newly cleaned text for comparison\n",
        "print(\"Original Text:\\n\", text_data)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "print(\"Cleaned Text (with spell check and improved punctuation/price handling):\\n\", cleaned_text_with_spellcheck)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.12/dist-packages (0.8.3)\n",
            "Original Text:\n",
            " \n",
            "Th√≠s √≠s √† pr√≥blem√°tic t√©xt f√≠le!! It contains **extra spaces** ,,,,, special characters!!!üí•üî•üöÄ\n",
            "Some words are misspelled, and encoding issues lik√© th√≠s c√§us√© probl√´ms.\n",
            "Prices are inconsistent: $29.99, 29.99 USD, 29,99$.\n",
            "Emails & phone numbers may be embedded: contact@domain.com, (123)-456-7890.\n",
            "Repeated punctuations!!!!! should be removed, along with **random symbols** like @@,##.\n",
            "stopwords like \"the\", \"is\", and \"a\" appear often.\n",
            "HTML tags might be present: <div>This is inside a div</div>\n",
            "And sometimes, contractions won't expand: \"can't\", \"won't\", \"shouldn't\".\n",
            "Random numeric values: 123456, 98765, 2024\n",
            "\n",
            "\n",
            "==================================================\n",
            "\n",
            "Cleaned Text (with spell check and improved punctuation/price handling):\n",
            " problematic text file contains extra spaces special characters words misspelled encoding issues like problems prices inconsistent $29.99 emails phone numbers may embedded repeated punctuations removed along random symbols like stopwords like appear often tags might present inside sometimes contractions expand cannot random numeric values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "cd07e192",
        "outputId": "24caa8e0-e175-46ed-f31a-826eb85719a8"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "file_name = \"cleaned_text.txt\"\n",
        "try:\n",
        "    files.download(file_name)\n",
        "except FileNotFoundError:\n",
        "    print(f\"File '{file_name}' not found. Please ensure the cleaning process was run and the file was saved.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_702e4a71-8455-4ab6-9a15-27cc94b39c52\", \"cleaned_text.txt\", 339)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8662cb8e",
        "outputId": "e9c3ceb7-65f1-468c-d918-845c980581d3"
      },
      "source": [
        "# Save the cleaned text to a file\n",
        "file_name = \"cleaned_text.txt\"\n",
        "with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(cleaned_text_with_spellcheck)\n",
        "\n",
        "print(f\"Cleaned text saved to {file_name}\")\n",
        "print(\"Please download this file again using the download button provided previously.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned text saved to cleaned_text.txt\n",
            "Please download this file again using the download button provided previously.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "05a51c2a",
        "outputId": "1dd84c5e-19b2-40f1-bab6-1e021bf91153"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "file_name = \"cleaned_text.txt\"\n",
        "try:\n",
        "    files.download(file_name)\n",
        "except FileNotFoundError:\n",
        "    print(f\"File '{file_name}' not found. Please ensure the cleaning process was run and the file was saved.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7827db60-cedd-49ad-9d87-7ebedb6364e2\", \"cleaned_text.txt\", 339)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}